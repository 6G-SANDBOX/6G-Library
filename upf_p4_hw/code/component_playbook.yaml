---
# Main playbook to deploy UPF-P4 HW Intel Tofino 2 component (with Open5Gs Control Plane component)

- name: "STAGE 1: Apply IAC to deploy Open5GS Control Plane component"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    - name: Load enviromental variables from different sources
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/load_variables.yaml"

    - name: Prepare terraform working directory
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/terraform_workdir.yaml"

    - name: Configure VM resources
      ansible.builtin.include_tasks: "{{ workspace }}/{{ component_type }}/code/{{ site_hypervisor }}/cac/01_pre/vm_resources.yaml"

    - name: Terraform apply
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/terraform_apply.yaml"


- name: "STAGE 2: Prepare access for Open5GS Control Plane and Bastion components"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    - name: Retrieve terraform outputs
      ansible.builtin.shell:
      args:
        chdir: "{{ workspace }}/.terraform/"
        cmd: "set -o pipefail && terraform output --json | jq 'with_entries(.value |= .value)'"
        executable: /bin/bash
      register: terraform_outputs
      changed_when: false

    - name: Verify terraform outputs
      ansible.builtin.assert:
        that:
          - terraform_outputs.stdout is defined
          - terraform_outputs.stdout | from_json is mapping
        fail_msg: "Invalid terraform outputs"

    - name: Validate terraform output variables
      ansible.builtin.assert:
        that:
          - (terraform_outputs.stdout | from_json)['tn_bastion-ips'] is defined
          - (terraform_outputs.stdout | from_json)['tn_ssh_public_key'] is defined
          - (terraform_outputs.stdout | from_json)[entity_name + '-ips'] is defined
          - (terraform_outputs.stdout | from_json)[entity_name + '-id'] is defined
        fail_msg: "Missing required terraform outputs"

    - name: Set Terraform outputs as playbook facts
      ansible.builtin.set_fact:
        bastion_ip: "{{ (terraform_outputs.stdout | from_json)['tn_bastion-ips'][site_networks_id.default | string] }}"
        tn_ssh_public_key: "{{ (terraform_outputs.stdout | from_json)['tn_ssh_public_key'] }}"
        ips: "{{ (terraform_outputs.stdout | from_json)[entity_name + '-ips'] }}"
        id: "{{ (terraform_outputs.stdout | from_json)[entity_name + '-id'] }}"
        access_vnet_id: "{{ (terraform_outputs.stdout | from_json)[one_upf_p4_hw_networks[0] + '-id'] | string }}"

    - name: Add new VM to Ansible Inventory
      ansible.builtin.add_host:
        hostname: "upf_p4_hw_open5gs"
        ansible_host: "{{ ips[access_vnet_id] }}"
        ansible_ssh_common_args: "-J jenkins@{{ bastion_ip }}"
        ansible_user: "jenkins"

    - name: Add the bastion VM to Ansible Inventory
      ansible.builtin.add_host:
        hostname: "bastion"
        ansible_host: "{{ bastion_ip }}"
        ansible_user: "jenkins"

    # While not used by the Jenkins, we included the configuration of a .ssh/config per TN in the Jenkins VM for debugging purposes.
    # If the configuration created doesn't fit your component, feel free to create another task file in your components cac/01_pre directory
    - name: Add new VM to SSH config file in the Jenkins-master for debugging purposes
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/jenkins_ssh_config.yaml"

    # In order to facilitate SSH connections to the experimenter, an aditional ssh config file for them can also be created.
    # If your component is not ment to be accessed by the experimenter (its not a VM or its a restricted one) do not configure ssh config for it
    - name: Add new VM to an SSH config file ment to be usable by the experimenter
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/tnuser_ssh_config.yaml"


- name: "STAGE 3.1: Apply CAC to configure the Open5GS Control Plane component"
  hosts: "upf_p4_hw_open5gs"
  gather_facts: false
  tasks:
    - name: Wait for system to become reachable
      ansible.builtin.wait_for_connection:
        connect_timeout: 5
        timeout: 200

    - name: Set site ssh key as authorized in jenkins user
      ansible.posix.authorized_key:
        user: jenkins
        state: present
        key: "{{ item }}"
      loop:
        - "{{ hostvars['localhost'].get('site_admin_ssh_public_key', '') }}"
      when: item != ''

    - name: Create new user for experimenter access
      become: true
      ansible.builtin.user:
        name: tnuser
        shell: /bin/bash
        groups: sudo
        password: ''

    - name: Set TN ssh key as authorized in new user
      become: true
      ansible.posix.authorized_key:
        user: tnuser
        state: present
        key: "{{ item }}"
      loop:
        - "{{ hostvars['localhost']['tn_ssh_public_key'] }}"

    - name: Open5GS Core Control install
      ansible.builtin.include_tasks:
        file: "{{ workspace }}/{{ component_type }}/code/{{ site_hypervisor }}/cac/02_install/open5gs_install.yaml"


- name: "STAGE 3.2: Apply CAC to configure the Bastion component"
  hosts: "bastion"
  gather_facts: false
  tasks:
    - name: Wait for system to become reachable
      ansible.builtin.wait_for_connection:
        connect_timeout: 5
        timeout: 200

    # TODO: Configure the bastion server as needed for the component.
    - name: Write firewall exception for the route-manager-api of your site
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/nftables_add.yaml"
      vars:
        fw_exceptions:
          - "{{ site_routemanager.api_endpoint }}"


- name: "STAGE 3.3: Apply CAC to configure Router Manager external component"
  hosts: localhost
  gather_facts: false
  tasks:
  # TODO: Configure routes in router manager component
    - name: Submit routes in route-manager-api from the Intel Tofino 2 CP to the Open5GS Core SMF (N4)
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/routemanager_add.yaml"
      vars:
        endpoint: "{{ site_routemanager.api_endpoint }}"
        token: "{{ site_routemanager.token }}"
      loop:
        - { to: "{{ one_upf_p4_hw_open5gs_smf_pfcp_addr }}", via: "{{ bastion_ip }}" }
    
    - name: Submit routes in route-manager-api from the Intel Tofino 2 DP N3 to the RAN (N3)
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/routemanager_add.yaml"
      vars:
        endpoint: "{{ site_routemanager.api_endpoint }}"
        token: "{{ site_routemanager.token }}"
      loop:
        - { to: "{{ one_upf_p4_hw_tofino2_enb_ipv4_n3 }}", via: "{{ bastion_ip }}" }

    - name: Submit routes in route-manager-api from the Intel Tofino 2 DP N6 to the PDN (N6)
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/routemanager_add.yaml"
      vars:
        endpoint: "{{ site_routemanager.api_endpoint }}"
        token: "{{ site_routemanager.token }}"
      loop:
        - { to: "{{ one_upf_p4_hw_tofino2_dn_ipv4_n6 }}", via: "{{ bastion_ip }}" }


- name: "STAGE 3.4: Apply CAC to configure the UPF HW Intel Tofino 2 external component"
  hosts: localhost
  gather_facts: false
  tasks:
    # Check initial status of the UPF Intel Tofino 2 component
    - name: "Check initial UPF status"
      ansible.builtin.uri:
        url: "http://{{ one_upf_p4_hw_open5gs_upf_pfcp_addr }}:8022/status"
        method: GET
        headers:
          Content-Type: "application/json"
        status_code: 200
        validate_certs: no
      register: initial_status
      
    - name: "Start UPF if not running"
      ansible.builtin.uri:
        url: "http://{{ one_upf_p4_hw_open5gs_upf_pfcp_addr }}:8022/start"
        method: POST
        headers:
          Content-Type: "application/json"
        body:
          smf_ipv4_n4: "{{ one_upf_p4_hw_open5gs_smf_pfcp_addr }}"
          enb_ipv4_n3: "{{ one_upf_p4_hw_tofino2_enb_ipv4_n3 }}"
          dn_ipv4_n6: "{{ one_upf_p4_hw_tofino2_dn_ipv4_n6 }}"
          subnet_ipv4: "{{ one_upf_p4_hw_ue_pool }}"
        body_format: json
        status_code: 200
        validate_certs: no
      register: start_result
      when: not initial_status.json.upf_running

    # Wait for 10 seconds after starting
    - name: "Wait for 10 seconds"
      ansible.builtin.pause:
        seconds: 10
      when: not initial_status.json.upf_running

    # Check final status
    - name: "Check final UPF status"
      ansible.builtin.uri:
        url: "http://{{ one_upf_p4_hw_open5gs_upf_pfcp_addr }}:8022/status"
        method: GET
        headers:
          Content-Type: "application/json"
        status_code: 200
        validate_certs: no
      register: final_status

    - name: "Debug final status"
      ansible.builtin.debug:
        var: final_status.json

# TODO
- name: "STAGE 4: Publish execution results"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    # You can publish files to the MINIO S3 Storage. By convention, please use misc-{{ entity_name }} as prefix
    # misc- files should be intended to be shared with the experimenter. They are PUBLIC.
    - name: Upload file to S3 object storage
      amazon.aws.s3_object:
        endpoint_url: "{{ site_s3_server.endpoint }}"
        mode: put
        access_key: "{{ lookup('ansible.builtin.env', 'AWS_ACCESS_KEY_ID') }}"
        secret_key: "{{ lookup('ansible.builtin.env', 'AWS_SECRET_ACCESS_KEY') }}"
        bucket: "{{ site_s3_server.bucket }}"
        object: "{{ tn_id }}/misc-{{ entity_name }}-something.yaml"
        content_base64: "{{ encoded_variable }}"
        encrypt: false
        validate_certs: false

    # Common task to create custom terraform outputs with information of interest for future component deployments.
    # Variables here may or may NOT be intended to be seen by the experimenters. They remain PRIVATE
    - name: Set custom terraform outputs for future components
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/custom_tf_outputs.yaml"
      vars:
        custom_outputs:
          - key: "{{ entity_name }}-node_ids"
            value: "{{ node_ids }}"
          - key: "{{ entity_name }}-node_ips"
            value: "{{ node_ips }}"

    # Necessary in most if not all components. Publishes the deployment information in the following order:
    # 1. Post the new terraform manifests to MINIO S3 Storage
    # 2. Generate markdown OK file with information about the component
    # 3. Post the markdown OK file to the MINIO S3 Storage
    # 4. Send a JSON OK notification to the TNLCM. JSON message also includes the markdown content.
    # Dictionary output should include the same variables as the markdown file, but in an indexable way for the TNLCM
    # Both the markdown and the variables sent to the TNLCM are intended to be shared with the experimenter. They are PUBLIC
    - name: Publish execution results to TNLCM and S3 object storage
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/publish_ok_results.yaml"
      vars:
        output:
          id: "{{ id | b64encode }}"
          node_ids: "{{ node_ids | b64encode }}"
          node_ips: "{{ node_ips | b64encode }}"
          kubeconfig: "{{ kubeconfig }}"  # if it's already encoded
          skooner_token: "{{ hostvars[entity_name + '-master_0']['skooner_token']['stdout'] | b64encode }}"
