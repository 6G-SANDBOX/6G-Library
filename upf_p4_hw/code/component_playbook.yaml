---
# Main playbook to deploy UPF-P4 HW Intel Tofino 2 component (with Open5Gs Control Plane component)

- name: "STAGE 1: Apply IAC to deploy Open5GS Control Plane component"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    - name: Load enviromental variables from different sources
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/load_variables.yaml"

    - name: Prepare terraform working directory
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/terraform_workdir.yaml"

    - name: Configure VM resources
      ansible.builtin.include_tasks: "{{ workspace }}/{{ component_type }}/code/{{ site_hypervisor }}/cac/01_pre/vm_resources.yaml"

    - name: Terraform apply
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/terraform_apply.yaml"


- name: "STAGE 2: Prepare access for Open5GS Control Plane and Bastion components"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    - name: Retrieve terraform outputs
      ansible.builtin.shell:
      args:
        chdir: "{{ workspace }}/.terraform/"
        cmd: "set -o pipefail && terraform output --json | jq 'with_entries(.value |= .value)'"
        executable: /bin/bash
      register: terraform_outputs
      changed_when: false

    - name: Verify terraform outputs
      ansible.builtin.assert:
        that:
          - terraform_outputs.stdout is defined
          - terraform_outputs.stdout | from_json is mapping
        fail_msg: "Invalid terraform outputs"

    - name: Validate terraform output variables
      ansible.builtin.assert:
        that:
          - (terraform_outputs.stdout | from_json)['tn_bastion-ips'] is defined
          - (terraform_outputs.stdout | from_json)['tn_ssh_public_key'] is defined
          - (terraform_outputs.stdout | from_json)[entity_name + '-ips'] is defined
          - (terraform_outputs.stdout | from_json)[entity_name + '-id'] is defined
        fail_msg: "Missing required terraform outputs"

    # access_vnet_id is used to identify the primary network interface of the Open5GS VM
    # This interface will be used for both management access and as SMF PFCP address
    - name: Set Terraform outputs as playbook facts
      ansible.builtin.set_fact:
        bastion_ip: "{{ (terraform_outputs.stdout | from_json)['tn_bastion-ips'][site_networks_id.default | string] }}"
        tn_ssh_public_key: "{{ (terraform_outputs.stdout | from_json)['tn_ssh_public_key'] }}"
        ips: "{{ (terraform_outputs.stdout | from_json)[entity_name + '-ips'] }}"
        id: "{{ (terraform_outputs.stdout | from_json)[entity_name + '-id'] }}"
        access_vnet_id: "{{ (terraform_outputs.stdout | from_json)[one_upf_p4_hw_open5gs_networks[0] + '-id'] | string }}"

    # Dynamically set the SMF PFCP address to the VM's tn_vxlan IP
    - name: Set SMF PFCP address to VM's tn_vxlan IP
      ansible.builtin.set_fact:
        one_upf_p4_hw_open5gs_smf_pfcp_addr: "{{ ips[access_vnet_id] }}"

    - name: Add new VM to Ansible Inventory
      ansible.builtin.add_host:
        hostname: "upf_p4_hw_open5gs"
        ansible_host: "{{ ips[access_vnet_id] }}"
        ansible_ssh_common_args: "-J jenkins@{{ bastion_ip }}"
        ansible_user: "jenkins"

    - name: Add the bastion VM to Ansible Inventory
      ansible.builtin.add_host:
        hostname: "bastion"
        ansible_host: "{{ bastion_ip }}"
        ansible_user: "jenkins"

    # While not used by the Jenkins, we included the configuration of a .ssh/config per TN in the Jenkins VM for debugging purposes.
    - name: Add new VM to SSH config file in the Jenkins-master for debugging purposes
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/jenkins_ssh_config.yaml"

    # In order to facilitate SSH connections to the experimenter, an aditional ssh config file for them can also be created.
    # If your component is not ment to be accessed by the experimenter (its not a VM or its a restricted one) do not configure ssh config for it
    - name: Add new VM to an SSH config file ment to be usable by the experimenter
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/tnuser_ssh_config.yaml"


- name: "STAGE 3.1: Apply CAC to configure the Open5GS Control Plane component"
  hosts: "upf_p4_hw_open5gs"
  gather_facts: false
  tasks:
    - name: Wait for system to become reachable
      ansible.builtin.wait_for_connection:
        connect_timeout: 5
        timeout: 200

    - name: Set site ssh key as authorized in jenkins user
      ansible.posix.authorized_key:
        user: jenkins
        state: present
        key: "{{ item }}"
      loop:
        - "{{ hostvars['localhost'].get('site_admin_ssh_public_key', '') }}"
      when: item != ''

    - name: Create new user for experimenter access
      become: true
      ansible.builtin.user:
        name: tnuser
        shell: /bin/bash
        groups: sudo
        password: ''

    - name: Set TN ssh key as authorized in new user
      become: true
      ansible.posix.authorized_key:
        user: tnuser
        state: present
        key: "{{ item }}"
      loop:
        - "{{ hostvars['localhost']['tn_ssh_public_key'] }}"

    ### Calling load_variables.yaml is unnecesary, as I can call localhost values with hostvars['localhost']['var_name'] or hostvars['localhost'].var_name"
    ### But it makes the code much MUCH cleaner with almost no extra latency
    - name: Load enviromental variables from different sources inside the component
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/load_variables.yaml"

    - name: Open5GS Core Control install
      ansible.builtin.include_tasks:
        file: "{{ workspace }}/{{ component_type }}/code/{{ site_hypervisor }}/cac/02_install/open5gs_install.yaml"


- name: "STAGE 3.2: Apply CAC to configure the Bastion component"
  hosts: "bastion"
  gather_facts: false
  tasks:
    - name: Wait for system to become reachable
      ansible.builtin.wait_for_connection:
        connect_timeout: 5
        timeout: 200

    ### Calling load_variables.yaml is unnecesary, as I can call localhost values with hostvars['localhost']['var_name'] or hostvars['localhost'].var_name"
    ### But it makes the code much MUCH cleaner with almost no extra latency
    - name: Load environmental variables from different sources inside the component
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/load_variables.yaml"

    # Configure the bastion server to permit IPs of the Intel Tofino 2 (N4, N3 and N6)
    #   - Used task .global/cac/nftables_add.yaml
    - name: Write firewall exception for the UPF Intel Tofino 2 interfaces
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/nftables_add.yaml"
      vars:
        fw_exceptions:
          - "{{ one_upf_p4_hw_open5gs_upf_pfcp_addr }}"
          - "{{ one_upf_p4_hw_tofino2_enb_ipv4_n3 }}"
          - "{{ one_upf_p4_hw_tofino2_dn_ipv4_n6 }}" 

    # Configure the bastion server to do DNAT with UDP port routing from the Intel Tofino 2 to internal TNs networks
    # Create directory for custom nftables rules if it doesn't exist
    - name: Ensure custom nftables rules directory exists
      ansible.builtin.file:
        path: /etc/nftables/custom_rules
        state: directory
        mode: '0755'
      become: true

    # I can use directly "{{ hostvars['localhost'].one_upf_p4_hw_open5gs_smf_pfcp_addr }}" but I prefer to set it as a fact again for clarity
    - name: Set SMF PFCP address in bastion context
      ansible.builtin.set_fact:
        one_upf_p4_hw_open5gs_smf_pfcp_addr: "{{ hostvars['localhost'].one_upf_p4_hw_open5gs_smf_pfcp_addr }}"

    # Create custom DNAT rules
    - name: Configure DNAT with UDP port routing for Tofino 2
      ansible.builtin.template:
        src: "{{ workspace }}/{{ component_type }}/code/one/cac/02_install/dnat_upf_rules.nft.j2"
        dest: /etc/nftables/custom_rules/dnat_upf_rules.nft
        owner: root
        group: root
        mode: '0644'
      become: true
      register: nft_rules_added

    # Reload nftables to apply new configuration
    - name: Reload nftables service
      ansible.builtin.systemd:
        name: nftables
        state: reloaded
      become: true
      when: nft_rules_added.changed
      register: nft_reload
      failed_when: nft_reload is failed

    # Verify nftables configuration after reload
    - name: Verify nftables configuration
      ansible.builtin.shell: nft list ruleset
      register: nft_list
      failed_when: false
      changed_when: false
      become: true
      when: nft_reload is changed

    # Debug nftables ruleset
    - name: Debug nftables ruleset
      ansible.builtin.debug:
        var: nft_list.stdout_lines
      when: nft_reload is changed


- name: "STAGE 3.3: Apply CAC to configure the UPF HW Intel Tofino 2 external component"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    # Check initial status of the UPF Intel Tofino 2 component
    - name: "Check initial UPF status"
      ansible.builtin.uri:
        url: "http://{{ one_upf_p4_hw_open5gs_upf_pfcp_addr }}:8022/status"
        method: GET
        headers:
          Content-Type: "application/json"
        status_code: [200, 502, 503, 504]
        validate_certs: no
        timeout: 10
      register: initial_status
      retries: 3
      delay: 5
      until: initial_status.status == 200
      failed_when: initial_status.status != 200 and initial_status.attempts|default(1) >= 3
      
    - name: "Start UPF if not running"
      ansible.builtin.uri:
        url: "http://{{ one_upf_p4_hw_open5gs_upf_pfcp_addr }}:8022/start"
        method: POST
        headers:
          Content-Type: "application/json"
        body:
          smf_ipv4_n4: "{{ bastion_ip }}"
          enb_ipv4_n3: "{{ bastion_ip }}"
          dn_ipv4_n6: "{{ one_upf_p4_hw_tofino2_dn_ipv4_n6 }}"
          subnet_ipv4: "{{ one_upf_p4_hw_ue_pool }}"
        body_format: json
        status_code: 200
        validate_certs: no
      register: start_result
      when: not initial_status.json.upf_running

    # Wait for 20 seconds after starting
    - name: "Wait for 20 seconds"
      ansible.builtin.pause:
        seconds: 20
      when: not initial_status.json.upf_running

    # Check final status
    - name: "Check final UPF status"
      ansible.builtin.uri:
        url: "http://{{ one_upf_p4_hw_open5gs_upf_pfcp_addr }}:8022/status"
        method: GET
        headers:
          Content-Type: "application/json"
        status_code: 200
        validate_certs: no
      register: final_status

    - name: "Debug final status"
      ansible.builtin.debug:
        var: final_status.json


- name: "STAGE 4: Publish execution results"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    # TODO: Maybe it is possible to put more field. For example, add the final UPF status information (final_status.json)
    - name: Define UPF-P4-HW(+Open5GS) metadata dictionary
      ansible.builtin.set_fact:
        upf_p4_hw_metadata_dict:
          {
            'proxy': '192.168.199.1',
            'mcc': '{{ one_upf_p4_hw_open5gs_control_mcc }}',
            'mnc': '{{ one_upf_p4_hw_open5gs_control_mnc }}',
            'msin': '{{ one_upf_p4_hw_open5gs_control_msin }}',
            'key': '{{ one_upf_p4_hw_open5gs_control_key }}',
            'opc': '{{ one_upf_p4_hw_open5gs_control_opc }}',
            'apn': '{{ one_upf_p4_hw_open5gs_control_apn }}',
            'tac': '{{ one_upf_p4_hw_open5gs_control_tac }}',
            's_nssai_sst': '{{ one_upf_p4_hw_open5gs_control_s_nssai_sst }}',
            's_nssai_sd': '{{ one_upf_p4_hw_open5gs_control_s_nssai_sd }}',
            'amf_ip': '{{ one_upf_p4_hw_open5gs_amf_ngap_addr }}',
            'upf_ip': '{{ one_upf_p4_hw_tofino2_enb_ipv4_n3 }}',
            'upf_ipv4_n6': '{{ one_upf_p4_hw_tofino2_dn_ipv4_n6 }}'
          }

    - name: Set custom terraform outputs for future components
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/custom_tf_outputs.yaml"
      vars:
        custom_outputs:
          - key: "{{ entity_name }}-metadata"
            value: "{{ upf_p4_hw_metadata_dict }}"

    - name: Publish execution results to TNLCM and S3 object storage
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/publish_ok_results.yaml"
