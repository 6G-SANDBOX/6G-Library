---
# Main playbook to deploy the component
# The different plays just serve as logical sepparations between deployment phases. If the "hosts" parameter of different plays is the same, feel free to join them
# This sample file will try to use as many public task files as possible, but your component may not need many of them. Feel free to use just the ones you need.
- name: "STAGE 1: Apply IAC to deploy the component"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:

    # Necessary in most if not all components. Loads the usable variables from 4 different sources in the following order:
    # 1. Site variables. Metadata unique to each site. Information like Image IDs, VNet IDs or ssh public keys.
    # 2. Private variables. Loads the component private values for the site hypervisor. File at {{ component_type }}/variables/{{ site_hypervisor }}/private.yaml
    # 3. Public variables. Loads the component input values as defined in the TNLCM/Jenkins. File is written and then read from {{ component_type }}/variables/input_file.yaml
    # 4. Pipeline parameters. Some of the parameters sent by the TNLCM to the Jenkins, like the custom_name or the the tnlcm_calback URL.
    #    File is written and then read from {{ component_type }}/variables/pipeline_parameters.yaml
    - name: Load enviromental variables from different sources
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/load_variables.yaml"

    # The variable "entity_name" is formed during the pipeline as {{ component_type }}-{{ custom_name }}
    # Some components like the tn_init can only be deployed once per TN.
    # In these components the custom name should not be required, and you can optionally supress it from the "entity_name" to avoid confusion
    # - name: Overwrite "entity_name" with only tn_init
    #   ansible.builtin.set_fact:
    #     entity_name: "tn_init"

    # Creates a terraform working directory at .terraform/, loads the MINIO backend and { site_hypervisor }} terraform provider files,
    # downloads manifests from previous deployments, and runs a single terraform init
    - name: Prepare terraform working directory
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/terraform_workdir.yaml"

    # Sometimes you may not need to deploy any new terraform component, but previous component outputs are still available.
    # - name: Retrieve terraform outputs
    #   ansible.builtin.shell:
    #   args:
    #     chdir: "{{ workspace }}/.terraform/"
    #     cmd: "set -o pipefail && terraform output --json | jq 'with_entries(.value |= .value)'"
    #     executable: /bin/bash
    #   register: terraform_outputs
    #   changed_when: false
    # - name: Set Terraform outputs as playbook facts
    #   ansible.builtin.set_fact:
    #     bastion_ip: "{{ (terraform_outputs.stdout | from_json)['tn_bastion-ips'][site_networks_id.default | string] }}"
    #     node_ips: "{{ (terraform_outputs.stdout | from_json)[one_open5gs_oneKE + '-node_ips'] }}"


    # More than just a simple terraform apply. Templates all manifests from {{ component_type }}/code/{{ site_hypervisor }}/iac/*.tf.j2, writes them
    # at .terraform and runs a terraform apply.
    # Task also has error handling, and if apply fails, will send a notification to the TNLCM with the stderr, and text from {{ component_type }}/result_templates/fail_result.md.j2
    - name: Terraform apply
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/terraform_apply.yaml"



# Post-terraform preliminary tasks. Still no component configuration.
- name: "STAGE 2: Prepare to access the component"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:

    # Module to retrieve all generated outputs from the terraform working directory in JSON with a key-value format
    - name: Retrieve terraform outputs
      ansible.builtin.shell:
      args:
        chdir: "{{ workspace }}/.terraform/"
        cmd: "set -o pipefail && terraform output --json | jq 'with_entries(.value |= .value)'"
        executable: /bin/bash
      register: terraform_outputs
      changed_when: false

    # Save some of the outputs as playbook facts (variables). Some of them will be surelly be used as future output values
    - name: Set Terraform outputs as playbook facts
      ansible.builtin.set_fact:
        bastion_ip: "{{ (terraform_outputs.stdout | from_json)['tn_bastion-ips'][site_networks_id.default | string] }}"
        tn_ssh_public_key: "{{ (terraform_outputs.stdout | from_json)['tn_ssh_public_key'] }}"
        ips: "{{ (terraform_outputs.stdout | from_json)[entity_name + '-ips'] }}"
        id: "{{ (terraform_outputs.stdout | from_json)[entity_name + '-id'] }}"
        vnet_id: "{{ (terraform_outputs.stdout | from_json)[one_vm_kvm_networks[0] + '-id'] | string}}"

    # Inclusion of a task file to to still do preliminatory tasks out of the main playbook
    - name: Fetch cluster node IPs
      ansible.builtin.include_tasks: "{{ workspace }}/{{ component_type }}/code/{{ site_hypervisor }}/cac/01_pre/node_ip.yaml"
      loop: "{{ cluster_roles | dict2items }}"

    # Include the deployed component/s as Inventory host/s.
    - name: Add new VM to Ansible Inventory
      ansible.builtin.add_host:
        hostname: "{{ entity_name }}"
        ansible_host: "{{ ips[ vnet_id ] }}"
        ansible_ssh_common_args: "-J jenkins@{{ bastion_ip }}"
        ansible_user: "jenkins"

    # While not used by the Jenkins, we included the configuration of a .ssh/config per TN in the Jenkins for debugging purposes.
    - name: Add new VMs to SSH config file in the Jenkins-master for debugging purposes
      ansible.builtin.include_tasks: "{{ workspace }}/{{ component_type }}/code/{{ site_hypervisor }}/cac/01_pre/ssh_config.yaml"
      loop: "{{ node_ips | dict2items }}"


# Configuration play. Modules executed in the deployment component.
# Remember in Ansible variables are loaded in each host, so if you change the host, you can either
# - Set the variables again (with the load_variables.yaml global taskfile or similar)
# - Refer to the hostvars of localhost.
- name: "STAGE 3: Apply CAC to prepare the component"
  hosts: "{{ hostvars['localhost']['entity_name'] }}"
  gather_facts: false
  tasks:
    - name: Wait for system to become reachable
      ansible.builtin.wait_for_connection:
        connect_timeout: 5
        timeout: 200

    # Some sites may have a MASTER ssh key, appart of the jenkins one
    - name: Set site ssh key as authorized in jenkins user
      ansible.posix.authorized_key:
        user: jenkins
        state: present
        key: "{{ item }}"
      loop:
        - "{{ hostvars['localhost'].get('site_admin_ssh_public_key', '') }}"
      when: item != ''

    # Any deployed VM should create a "tnuser" user for the experimenter's access. All components can be accessed through that user with the ssh key created in tn_init
    - name: Create new user for experimenter access
      become: true
      ansible.builtin.user:
        name: tnuser
        shell: /bin/bash
        groups: sudo
    - name: Set TN ssh key as authorized in new user
      become: true
      ansible.posix.authorized_key:
        user: tnuser
        state: present
        key: "{{ item }}"
      loop:
        - "{{ hostvars['localhost']['tn_ssh_public_key'] }}"

    # Example of inclued task files common to all hypervisors, like helm charts, or bash/python/ruby sripts.
    - name: Helm install
      ansible.builtin.include_tasks: "{{ workspace }}/{{ component_type }}/code/all/cac/helm_install.yaml"


# Final phase of the deployments. Gather information and publish it
- name: "STAGE 4: Publish execution results"
  hosts: localhost
  gather_facts: false
  connection: local
  tasks:
    # You can publish files to the MINIO S3 Storage
    - name: Upload kubeconfig to S3
      amazon.aws.s3_object:
        endpoint_url: "{{ site_s3_server.endpoint }}"
        mode: put
        access_key: "{{ lookup('ansible.builtin.env', 'AWS_ACCESS_KEY_ID') }}"
        secret_key: "{{ lookup('ansible.builtin.env', 'AWS_SECRET_ACCESS_KEY') }}"
        bucket: "{{ site_s3_server.bucket }}"
        object: "{{ tn_id }}/kconf-{{ entity_name }}.kubeconfig"
        src: "{{ workspace }}/{{ component_type }}/code/{{ entity_name }}.kubeconfig"
        encrypt: false
        validate_certs: false

    # Common task to create custom terraform outputs with information of interest for future deployments.
    - name: Publish node IDs and IPs as a terraform outputs"
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/custom_tf_outputs.yaml"
      vars:
        custom_outputs:
          - key: "{{ entity_name }}-node_ids"
            value: "{{ node_ids }}"
          - key: "{{ entity_name }}-node_ips"
            value: "{{ node_ips }}"

    # Necessary in most if not all components. Publishes the deployment information in the following order:
    # 1. Post the new terraform manifests to MINIO S3 Storage
    # 2. Generate markdown OK file with information about the component
    # 3. Post the markdown OK file to the MINIO S3 Storage
    # 4. Send a JSON OK notification to the TNLCM. JSON message also includes the markdown content.
    - name: Publish execution results to TNLCM
      ansible.builtin.include_tasks: "{{ workspace }}/.global/cac/publish_ok_results.yaml"
      vars:
        output:
          id: "{{ id | b64encode }}"
          node_ids: "{{ node_ids | b64encode }}"
          node_ips: "{{ node_ips | b64encode }}"
          kubeconfig: "{{ kubeconfig | b64encode }}"
          skooner_token: "{{ hostvars[entity_name + '-master_0']['skooner_token']['stdout'] | b64encode }}"
